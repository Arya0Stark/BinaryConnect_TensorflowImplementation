# -*- coding: utf-8 -*-
"""Grad_Funtions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Eg-s-H30KUVngt1sex5483juXVoxNZfg
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import time
import tensorflow as tf
from tensorflow.keras.layers import Layer
from tensorflow.keras import initializers
from tensorflow.keras import backend as K
from __future__ import print_function

import sys
import os
import time
import tensorflow as tf
from tensorflow.keras.layers import Input, Dropout, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError, Hinge
from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy
import numpy as np
fashion_mnist = tf.keras.datasets.fashion_mnist
import pandas as pd
from tensorflow.keras.layers import Input, Dropout, Flatten
from tensorflow.keras.models import Model

import numpy as np
np.random.seed(1234)  # for reproducibility

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from sklearn.utils import shuffle

from collections import OrderedDict

# compute gradients for BinaryConnect layers
def compute_grads(loss, network):
    grads = []
    for layer in network.layers:
        if hasattr(layer, 'Wb'):
            grads.append(tf.gradients(loss, layer.Wb)[0])
    return grads

# apply clipping and scaling to BinaryConnect layer updates
def clipping_scaling(updates, model):
    clipped_updates = {}

    for layer in model.layers:
        if isinstance(layer, DenseLayer):
            lr_scaled_update = layer.W_LR_scale * (layer.Wb - layer.W)
            clipped_update = tf.clip_by_value(layer.W + lr_scaled_update, -layer.H, layer.H)
            clipped_updates[layer.W.ref()] = clipped_update

    return clipped_updates