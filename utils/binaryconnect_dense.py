# -*- coding: utf-8 -*-
"""BinaryConnect_Dense.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15qvBOSLdMN9Nx5gPloflWP8I88S-JMtD
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import time
import tensorflow as tf
from tensorflow.keras.layers import Layer
from tensorflow.keras import initializers
from tensorflow.keras import backend as K
from __future__ import print_function

import sys
import os
import time
import tensorflow as tf
from tensorflow.keras.layers import Input, Dropout, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError, Hinge
from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy
import numpy as np
fashion_mnist = tf.keras.datasets.fashion_mnist
import pandas as pd
from tensorflow.keras.layers import Input, Dropout, Flatten
from tensorflow.keras.models import Model

import numpy as np
np.random.seed(1234)  # for reproducibility

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from sklearn.utils import shuffle

from collections import OrderedDict

class DenseLayer(tf.keras.layers.Layer):
    def __init__(self, units, binary=True, stochastic=True, H=1.0, W_LR_scale="Glorot", **kwargs):
        super(DenseLayer, self).__init__(**kwargs)
        self.units = units
        self.binary = binary
        self.stochastic = stochastic
        self.H = H
        self.W_LR_scale = W_LR_scale
        self.seed = tf.constant([42, 42], dtype=tf.int32)  # Set your desired seed values
        self.W = None  # Initialize W to None

        if W_LR_scale == "Glorot":
            self.W_LR_scale = None  # Set to None initially
        elif isinstance(W_LR_scale, str) and W_LR_scale.lower() == "none":
            self.W_LR_scale = 1.0  # or any default value you prefer

    def build(self, input_shape):
        if self.W is None:
            input_dim = tf.TensorShape(input_shape[-1]).as_list()[0]
            self.units = self.units if self.units is not None else 1
            # Initialize binary weights using RandomUniform distribution
            self.W = self.add_weight(
                name='kernel',
                shape=(input_dim, self.units),
                initializer=tf.initializers.RandomUniform(-self.H, self.H),
                trainable=True
            )

            if self.W_LR_scale is None:
                self.W_LR_scale = 1.0 / np.sqrt(1.5 / (self.units + input_dim))

        super(DenseLayer, self).build(input_shape)

    def call(self, inputs, training=None, **kwargs):
        # Apply BinaryConnect binarization to weights
        self.Wb = binarization(self.W, self.H, self.binary, not training, self.stochastic, self.seed)
        Wr = self.W
        self.W = self.Wb
        output = tf.matmul(inputs, self.W)
        self.W = Wr
        return output